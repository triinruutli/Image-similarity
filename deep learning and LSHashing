!pip install lshash3

import pandas as pd
import pickle
import numpy as np
from fastai.vision import *
from fastai.callbacks.hooks import *
import matplotlib
import matplotlib.pyplot as plt
from lshash import lshash
from PIL import Image 
from tqdm import tqdm_notebook
pd.set_option('display.max_columns', 500)

#!tar -xf 101_ObjectCategories.tar.gz
!unzip 101_ObjectCategories.zip

path='/content/101_ObjectCategories/'
tfms = get_transforms(
    do_flip=False, 
    flip_vert=False, 
    max_rotate=0, 
    max_lighting=0, 
    max_zoom=1, 
    max_warp=0
)
data = (ImageList.from_folder(path)
        .split_by_rand_pct(0.2)
        .label_from_folder()
        .transform(tfms=tfms, size=224)
        .databunch(bs=16))
				
print('Train dataset size: {0}'.format(len(data.train_ds.x)))
print('Test dataset size: {0}'.format(len(data.valid_ds.x)))

## Show sample data
data.show_batch(rows=3, figsize=(10,6), hide_axis=False)

## Creating the model
learn = cnn_learner(data, models.resnet34, pretrained=True, metrics=accuracy)
#cnn_learner funktsioon juba freezib etteantud mudeli backbone'i

learn.lr_find()
learn.recorder.plot()

learn.fit_one_cycle(5,1e-2)
learn.save('stg1-rn34')

## Unfreeing layer and finding ideal learning rate
learn.unfreeze()
learn.lr_find()
learn.recorder.plot()

learn.fit_one_cycle(5, slice(1e-5, 1e-4))

## Saving model weights
learn.save('stg2-rn34')

class SaveFeatures():
    features=None
    def __init__(self, m): 
        self.hook = m.register_forward_hook(self.hook_fn)
        self.features = None
    def hook_fn(self, module, input, output): 
        out = output.detach().cpu().numpy()
        if isinstance(self.features, type(None)):
            self.features = out
        else:
            self.features = np.row_stack((self.features, out))
    def remove(self): 
        self.hook.remove()
     
sf = SaveFeatures(learn.model[1][5]) ## Output before the last FC layer

_= learn.get_preds(data.train_ds)
_= learn.get_preds(DatasetType.Valid)

import csv

img_path = [str(x) for x in (list(data.train_ds.items)+list(data.valid_ds.items))]
feature_dict = dict(zip(img_path,sf.features))

pickle.dump(feature_dict, open('101_ObjectCategories/feature_dict.p', 'wb'))

feature_dict = pickle.load(open('101_ObjectCategories/feature_dict.p','rb'))

## Locality Sensitive Hashing
# params
k = 10 # hash size
L = 5  # number of tables
d = 512 # Dimension of Feature vector
lsh = lshash.LSHash(hash_size=k, input_dim=d, num_hashtables=L)

# LSH on all the images
for img_path, vec in tqdm_notebook(feature_dict.items()):
    lsh.index(vec.flatten(), extra_data=img_path)
		
pickle.dump(lsh, open('101_ObjectCategories/lsh.p', "wb"))

from PIL import Image 

feature_dict = pickle.load(open('101_ObjectCategories/feature_dict.p','rb'))
lsh = pickle.load(open('101_ObjectCategories/lsh.p','rb'))

def get_similar_item(idx, feature_dict, lsh_variable, n_items=5):
    response = lsh_variable.query(feature_dict[list(feature_dict.keys())[idx]].flatten(), 
                     num_results=n_items+1, distance_func='hamming')
    
    columns = 3
    rows = int(np.ceil(n_items+1/columns))
    fig=plt.figure(figsize=(2*rows, 3*rows))
    for i in range(1, columns*rows +1):
        if i<n_items+2:
            img = Image.open(response[i-1][0][1])
            fig.add_subplot(rows, columns, i)
            plt.imshow(img)
    return plt.show()
		
get_similar_item(9, feature_dict, lsh,5)
